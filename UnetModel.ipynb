{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOCHUBC0o1eJsBm4L4/DvcD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Divak-ar/floorData/blob/master/UnetModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.morphology import skeletonize\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, BatchNormalization, Activation\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "import json\n",
        "import shutil\n",
        "import glob\n",
        "\n",
        "# Set parameters\n",
        "IMG_HEIGHT = 512\n",
        "IMG_WIDTH = 512\n",
        "BATCH_SIZE = 4\n",
        "EPOCHS = 60\n",
        "\n",
        "# Check if running in Colab\n",
        "def is_colab():\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "# Create directories for the project\n",
        "def setup_directories():\n",
        "    \"\"\"Create directories for the project\"\"\"\n",
        "    os.makedirs('dataset', exist_ok=True)\n",
        "    os.makedirs('dataset/walls', exist_ok=True)\n",
        "    os.makedirs('dataset/model', exist_ok=True)\n",
        "    os.makedirs('dataset/test', exist_ok=True)\n",
        "    os.makedirs('dataset/results', exist_ok=True)\n",
        "\n",
        "    print(\"Directory structure created:\")\n",
        "    print(\"- dataset/walls: Upload your wall images here\")\n",
        "    print(\"- dataset/test: Upload your test images here\")\n",
        "    print(\"- dataset/model: Trained models will be saved here\")\n",
        "    print(\"- dataset/results: Results will be saved here\")\n",
        "\n",
        "# Upload files to Google Colab\n",
        "def upload_files(target_dir='dataset/walls'):\n",
        "    \"\"\"Upload files to the target directory in Google Colab\"\"\"\n",
        "    print(f\"Please upload your images to {target_dir}...\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    # Move uploaded files to target directory\n",
        "    for filename in uploaded.keys():\n",
        "        dest_path = os.path.join(target_dir, filename)\n",
        "        # Create the target directory if it doesn't exist\n",
        "        os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
        "        # Move the file\n",
        "        shutil.move(filename, dest_path)\n",
        "\n",
        "    print(f\"Uploaded {len(uploaded)} files to {target_dir}\")\n",
        "    return list(uploaded.keys())\n",
        "\n",
        "# Create a simplified U-Net model specifically for wall detection\n",
        "def simple_unet(input_shape=(512, 512, 1)):\n",
        "    \"\"\"A simplified U-Net for wall detection\"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    # Encoder (downsampling)\n",
        "    conv1 = Conv2D(32, 3, padding='same')(inputs)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    conv1 = Conv2D(32, 3, padding='same')(conv1)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Activation('relu')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, 3, padding='same')(pool1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    conv2 = Conv2D(64, 3, padding='same')(conv2)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation('relu')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, 3, padding='same')(pool2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "    conv3 = Conv2D(128, 3, padding='same')(conv3)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Activation('relu')(conv3)\n",
        "\n",
        "    # Decoder (upsampling)\n",
        "    up2 = UpSampling2D(size=(2, 2))(conv3)\n",
        "    up2 = concatenate([conv2, up2], axis=3)\n",
        "\n",
        "    conv4 = Conv2D(64, 3, padding='same')(up2)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    conv4 = Activation('relu')(conv4)\n",
        "    conv4 = Conv2D(64, 3, padding='same')(conv4)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    conv4 = Activation('relu')(conv4)\n",
        "\n",
        "    up1 = UpSampling2D(size=(2, 2))(conv4)\n",
        "    up1 = concatenate([conv1, up1], axis=3)\n",
        "\n",
        "    conv5 = Conv2D(32, 3, padding='same')(up1)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    conv5 = Activation('relu')(conv5)\n",
        "    conv5 = Conv2D(32, 3, padding='same')(conv5)\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    conv5 = Activation('relu')(conv5)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = Conv2D(1, 1, activation='sigmoid')(conv5)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Load and preprocess data\n",
        "def load_data_walls_only(walls_dir):\n",
        "    \"\"\"Load wall masks only for training\"\"\"\n",
        "    masks = []\n",
        "\n",
        "    # List all files in the directory\n",
        "    wall_files = sorted(os.listdir(walls_dir))\n",
        "\n",
        "    if not wall_files:\n",
        "        print(f\"No files found in {walls_dir}. Please upload some wall images.\")\n",
        "        return None\n",
        "\n",
        "    print(f\"Loading {len(wall_files)} files from {walls_dir}...\")\n",
        "\n",
        "    for wall_file in wall_files:\n",
        "        # Skip hidden files\n",
        "        if wall_file.startswith('.'):\n",
        "            continue\n",
        "\n",
        "        # Load wall mask\n",
        "        wall_path = os.path.join(walls_dir, wall_file)\n",
        "        mask = cv2.imread(wall_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        # Skip if file couldn't be read\n",
        "        if mask is None:\n",
        "            print(f\"Warning: Could not read file {wall_path}\")\n",
        "            continue\n",
        "\n",
        "        mask = cv2.resize(mask, (IMG_WIDTH, IMG_HEIGHT))\n",
        "        mask = np.expand_dims(mask, axis=-1)\n",
        "        mask = (mask > 127).astype(np.float32)  # Binarize\n",
        "\n",
        "        # Use the mask as both input and output\n",
        "        masks.append(mask)\n",
        "\n",
        "    if len(masks) == 0:\n",
        "        raise ValueError(f\"No valid mask files found in {walls_dir}\")\n",
        "\n",
        "    return np.array(masks)\n",
        "\n",
        "# Train the model\n",
        "def train_simple_model(data_dir='dataset'):\n",
        "    \"\"\"Train the simple wall detection model\"\"\"\n",
        "    # Load data\n",
        "    walls_dir = os.path.join(data_dir, 'walls')\n",
        "\n",
        "    # Create directories if they don't exist\n",
        "    os.makedirs(os.path.join(data_dir, 'model'), exist_ok=True)\n",
        "\n",
        "    # Check if walls directory has files\n",
        "    if not os.listdir(walls_dir):\n",
        "        print(f\"No files found in {walls_dir}. Please upload wall images first.\")\n",
        "        return None, None\n",
        "\n",
        "    print(\"Loading data...\")\n",
        "    masks = load_data_walls_only(walls_dir)\n",
        "\n",
        "    if masks is None:\n",
        "        return None, None\n",
        "\n",
        "    print(f\"Loaded {len(masks)} mask files\")\n",
        "\n",
        "    # Use masks as both input and output\n",
        "    inputs = masks.copy()\n",
        "\n",
        "    # Normalize inputs\n",
        "    inputs = inputs.astype('float32') / 255.0\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_val, Y_train, Y_val = train_test_split(\n",
        "        inputs, masks, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"Training shapes: X={X_train.shape}, Y={Y_train.shape}\")\n",
        "    print(f\"Validation shapes: X={X_val.shape}, Y={Y_val.shape}\")\n",
        "\n",
        "    # Create model\n",
        "    print(\"Creating model...\")\n",
        "    model = simple_unet(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1))\n",
        "\n",
        "    # Print model summary\n",
        "    model.summary()\n",
        "\n",
        "    # Compile\n",
        "    model.compile(\n",
        "        optimizer=Adam(learning_rate=1e-4),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=2)]\n",
        "    )\n",
        "\n",
        "    # Callbacks\n",
        "    model_path = os.path.join(data_dir, 'model', 'simple_walls_best.h5')\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(\n",
        "            model_path,\n",
        "            save_best_only=True,\n",
        "            monitor='val_mean_io_u',\n",
        "            mode='max'\n",
        "        ),\n",
        "        EarlyStopping(\n",
        "            patience=10,\n",
        "            monitor='val_mean_io_u',\n",
        "            mode='max',\n",
        "            restore_best_weights=True\n",
        "        ),\n",
        "        ReduceLROnPlateau(\n",
        "            factor=0.2,\n",
        "            patience=5,\n",
        "            min_lr=1e-6,\n",
        "            monitor='val_mean_io_u',\n",
        "            mode='max'\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    # Train\n",
        "    print(\"Training model...\")\n",
        "    history = model.fit(\n",
        "        X_train, Y_train,\n",
        "        validation_data=(X_val, Y_val),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    # Save final model\n",
        "    final_model_path = os.path.join(data_dir, 'model', 'simple_walls_final.h5')\n",
        "    model.save(final_model_path)\n",
        "    print(f\"Model saved to {final_model_path}\")\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "    # Fix for the MeanIoU metric name issue\n",
        "    iou_key = None\n",
        "    val_iou_key = None\n",
        "\n",
        "    # Find the correct keys for IoU metrics in history\n",
        "    for key in history.history.keys():\n",
        "        if 'io_u' in key.lower() and not key.startswith('val_'):\n",
        "            iou_key = key\n",
        "        elif 'io_u' in key.lower() and key.startswith('val_'):\n",
        "            val_iou_key = key\n",
        "\n",
        "    if iou_key and val_iou_key:\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history[iou_key])\n",
        "        plt.plot(history.history[val_iou_key])\n",
        "        plt.title('Mean IoU')\n",
        "        plt.ylabel('IoU')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "    else:\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history['accuracy'])\n",
        "        plt.plot(history.history['val_accuracy'])\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    history_path = os.path.join(data_dir, 'training_history.png')\n",
        "    plt.savefig(history_path)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Training history saved to {history_path}\")\n",
        "\n",
        "    return model, history\n",
        "\n",
        "def get_walls_coordinates(model, image_path, min_length=20, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Extract wall coordinates in (x1, y1, x2, y2, length) format\n",
        "\n",
        "    Args:\n",
        "        model: Trained wall detection model\n",
        "        image_path: Path to input floor plan image\n",
        "        min_length: Minimum length of wall segments to detect\n",
        "        threshold: Threshold for binary mask prediction\n",
        "\n",
        "    Returns:\n",
        "        numpy array of shape (n, 5) with each row containing (x1, y1, x2, y2, length)\n",
        "    \"\"\"\n",
        "    # Load and preprocess image\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    # Check if image was loaded successfully\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not read image at {image_path}\")\n",
        "        return None\n",
        "\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    img_gray = cv2.resize(img_gray, (IMG_WIDTH, IMG_HEIGHT))\n",
        "    img_gray = np.expand_dims(img_gray, axis=-1)\n",
        "    img_norm = img_gray.astype('float32') / 255.0\n",
        "\n",
        "    # Predict mask\n",
        "    pred_mask = model.predict(np.expand_dims(img_norm, axis=0))[0]\n",
        "    binary_mask = (pred_mask > threshold).astype(np.uint8) * 255\n",
        "\n",
        "    # Clean the mask\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    binary_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # Get the centerlines\n",
        "    skeleton = skeletonize(binary_mask[:,:,0] > 0).astype(np.uint8) * 255\n",
        "\n",
        "    # Use Hough transform to get line segments\n",
        "    lines = cv2.HoughLinesP(\n",
        "        skeleton,\n",
        "        rho=1,\n",
        "        theta=np.pi/180,\n",
        "        threshold=10,\n",
        "        minLineLength=min_length,\n",
        "        maxLineGap=10\n",
        "    )\n",
        "\n",
        "    # Prepare output array\n",
        "    wall_coords = []\n",
        "\n",
        "    if lines is not None:\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            length = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
        "            wall_coords.append([x1, y1, x2, y2, length])\n",
        "\n",
        "    return np.array(wall_coords) if wall_coords else np.empty((0, 5))\n",
        "\n",
        "def save_wall_coordinates_csv(wall_coords, output_path):\n",
        "    \"\"\"\n",
        "    Save wall coordinates to CSV file\n",
        "\n",
        "    Args:\n",
        "        wall_coords: numpy array of wall coordinates (x1, y1, x2, y2, length)\n",
        "        output_path: Path to save the CSV file\n",
        "    \"\"\"\n",
        "    # Create output directory if needed\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "    # Save to CSV\n",
        "    np.savetxt(\n",
        "        output_path,\n",
        "        wall_coords,\n",
        "        delimiter=',',\n",
        "        header='x1,y1,x2,y2,length',\n",
        "        comments='',\n",
        "        fmt='%d,%d,%d,%d,%.2f'\n",
        "    )\n",
        "\n",
        "    print(f\"Wall coordinates saved to {output_path}\")\n",
        "\n",
        "    # If in Colab, download the file\n",
        "    if is_colab():\n",
        "        files.download(output_path)\n",
        "\n",
        "def extract_wall_coordinates(pred_mask, min_length=20):\n",
        "    \"\"\"\n",
        "    Extract wall coordinates as line segments from prediction mask\n",
        "\n",
        "    Returns:\n",
        "        List of wall segments with start/end points and length\n",
        "    \"\"\"\n",
        "    # Ensure binary mask\n",
        "    binary = (pred_mask > 0).astype(np.uint8)\n",
        "\n",
        "    # Clean the mask\n",
        "    kernel = np.ones((3,3), np.uint8)\n",
        "    binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # Get the centerlines\n",
        "    skeleton = skeletonize(binary).astype(np.uint8) * 255\n",
        "\n",
        "    # Use Hough transform to get line segments\n",
        "    lines = cv2.HoughLinesP(\n",
        "        skeleton,\n",
        "        rho=1,\n",
        "        theta=np.pi/180,\n",
        "        threshold=10,\n",
        "        minLineLength=min_length,\n",
        "        maxLineGap=10\n",
        "    )\n",
        "\n",
        "    wall_segments = []\n",
        "    if lines is not None:\n",
        "        for i, line in enumerate(lines):\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            length = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
        "\n",
        "            wall_segments.append({\n",
        "                \"id\": i,\n",
        "                \"points\": [\n",
        "                    {\"x\": int(x1), \"y\": int(y1)},\n",
        "                    {\"x\": int(x2), \"y\": int(y2)}\n",
        "                ],\n",
        "                \"length\": float(length)\n",
        "            })\n",
        "\n",
        "    return wall_segments, skeleton\n",
        "\n",
        "def predict_walls(model, image_path, result_dir='dataset/results'):\n",
        "    \"\"\"Predict walls and extract line segments\"\"\"\n",
        "    # Create results directory if it doesn't exist\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    # Get base filename without extension\n",
        "    base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "    # Load and preprocess image\n",
        "    img = cv2.imread(image_path)\n",
        "    # Check if image was loaded successfully\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not read image at {image_path}\")\n",
        "        return None, None\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "    # For wall-to-wall model, we need a grayscale version\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    img_gray = np.expand_dims(img_gray, axis=-1)\n",
        "    img_norm = img_gray.astype('float32') / 255.0\n",
        "\n",
        "    # Predict mask\n",
        "    pred_mask = model.predict(np.expand_dims(img_norm, axis=0))[0]\n",
        "    binary_mask = (pred_mask > 0.5).astype(np.uint8) * 255\n",
        "\n",
        "    # Extract wall coordinates\n",
        "    wall_segments, skeleton = extract_wall_coordinates(binary_mask)\n",
        "\n",
        "    # Visualize\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    # Original image\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"Original Floor Plan\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Predicted mask\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.imshow(binary_mask[:,:,0], cmap='gray')\n",
        "    plt.title(\"Predicted Wall Mask\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Skeleton\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.imshow(skeleton, cmap='gray')\n",
        "    plt.title(\"Wall Skeleton\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Wall lines\n",
        "    plt.subplot(2, 2, 4)\n",
        "    line_img = img.copy()\n",
        "    for wall in wall_segments:\n",
        "        p1 = wall['points'][0]\n",
        "        p2 = wall['points'][1]\n",
        "        cv2.line(line_img, (p1['x'], p1['y']), (p2['x'], p2['y']), (0, 0, 255), 2)\n",
        "\n",
        "    plt.imshow(line_img)\n",
        "    plt.title(f\"Detected Wall Lines ({len(wall_segments)} segments)\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save visualization\n",
        "    viz_path = os.path.join(result_dir, f\"{base_filename}_visualization.png\")\n",
        "    plt.savefig(viz_path)\n",
        "    plt.show()\n",
        "\n",
        "    # Save wall data to JSON\n",
        "    wall_data = {\n",
        "        \"walls\": wall_segments,\n",
        "        \"imageWidth\": IMG_WIDTH,\n",
        "        \"imageHeight\": IMG_HEIGHT,\n",
        "        \"scale\": 0.02  # 1 pixel = 2cm (example scale)\n",
        "    }\n",
        "\n",
        "    json_path = os.path.join(result_dir, f\"{base_filename}_wall_coordinates.json\")\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(wall_data, f, indent=2)\n",
        "\n",
        "    print(f\"Found {len(wall_segments)} wall segments\")\n",
        "    print(f\"Wall coordinates saved to {json_path}\")\n",
        "    print(f\"Visualization saved to {viz_path}\")\n",
        "\n",
        "    # If in Colab, download the files\n",
        "    if is_colab():\n",
        "        print(\"Downloading results...\")\n",
        "        files.download(json_path)\n",
        "        files.download(viz_path)\n",
        "\n",
        "    return wall_segments, binary_mask\n",
        "\n",
        "# Simple direct wall extraction without deep learning\n",
        "def extract_walls_directly(image_path, result_dir='dataset/results'):\n",
        "    \"\"\"Extract walls directly from binary wall image (no deep learning)\"\"\"\n",
        "    # Create results directory if it doesn't exist\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    # Get base filename without extension\n",
        "    base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "    # Read image (assuming walls are white on black background)\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "    # Check if image was loaded successfully\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not read image at {image_path}\")\n",
        "        return None\n",
        "\n",
        "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "    # Binarize if needed\n",
        "    _, binary = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Skeletonize\n",
        "    skeleton = skeletonize(binary > 0).astype(np.uint8) * 255\n",
        "\n",
        "    # Detect lines\n",
        "    lines = cv2.HoughLinesP(\n",
        "        skeleton,\n",
        "        rho=1,\n",
        "        theta=np.pi/180,\n",
        "        threshold=15,\n",
        "        minLineLength=30,\n",
        "        maxLineGap=10\n",
        "    )\n",
        "\n",
        "    # Process lines\n",
        "    wall_segments = []\n",
        "    if lines is not None:\n",
        "        for i, line in enumerate(lines):\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            length = np.sqrt((x2-x1)**2 + (y2-y1)**2)\n",
        "\n",
        "            wall_segments.append({\n",
        "                \"id\": i,\n",
        "                \"points\": [\n",
        "                    {\"x\": int(x1), \"y\": int(y1)},\n",
        "                    {\"x\": int(x2), \"y\": int(y2)}\n",
        "                ],\n",
        "                \"length\": float(length)\n",
        "            })\n",
        "\n",
        "    # Visualize\n",
        "    rgb_img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(\"Binary Wall Image\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(skeleton, cmap='gray')\n",
        "    plt.title(\"Wall Skeleton\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    line_img = rgb_img.copy()\n",
        "    for wall in wall_segments:\n",
        "        p1 = wall['points'][0]\n",
        "        p2 = wall['points'][1]\n",
        "        cv2.line(line_img, (p1['x'], p1['y']), (p2['x'], p2['y']), (0, 0, 255), 2)\n",
        "\n",
        "    plt.imshow(line_img)\n",
        "    plt.title(f\"Detected Wall Lines ({len(wall_segments)} segments)\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save visualization\n",
        "    viz_path = os.path.join(result_dir, f\"{base_filename}_direct_visualization.png\")\n",
        "    plt.savefig(viz_path)\n",
        "    plt.show()\n",
        "\n",
        "    # Save wall data\n",
        "    wall_data = {\n",
        "        \"walls\": wall_segments,\n",
        "        \"imageWidth\": IMG_WIDTH,\n",
        "        \"imageHeight\": IMG_HEIGHT,\n",
        "        \"scale\": 0.02\n",
        "    }\n",
        "\n",
        "    json_path = os.path.join(result_dir, f\"{base_filename}_direct_wall_coordinates.json\")\n",
        "    with open(json_path, 'w') as f:\n",
        "        json.dump(wall_data, f, indent=2)\n",
        "\n",
        "    print(f\"Found {len(wall_segments)} wall segments\")\n",
        "    print(f\"Wall coordinates saved to {json_path}\")\n",
        "    print(f\"Visualization saved to {viz_path}\")\n",
        "\n",
        "    # If in Colab, download the files\n",
        "    if is_colab():\n",
        "        print(\"Downloading results...\")\n",
        "        files.download(json_path)\n",
        "        files.download(viz_path)\n",
        "\n",
        "    return wall_segments\n",
        "\n",
        "# Test the model on all images in the test directory\n",
        "def test_model(model, test_dir='dataset/test', result_dir='dataset/results'):\n",
        "    \"\"\"Test the model on all images in the test directory\"\"\"\n",
        "    # Create results directory if it doesn't exist\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    # Get list of test images\n",
        "    test_images = glob.glob(os.path.join(test_dir, '*.*'))\n",
        "\n",
        "    # Check if there are any test images\n",
        "    if not test_images:\n",
        "        print(f\"No test images found in {test_dir}. Please upload some test images first.\")\n",
        "        return\n",
        "\n",
        "    print(f\"Testing model on {len(test_images)} images...\")\n",
        "\n",
        "    # Process each test image\n",
        "    all_results = {}\n",
        "\n",
        "    for img_path in test_images:\n",
        "        print(f\"Processing {os.path.basename(img_path)}...\")\n",
        "        wall_segments, _ = predict_walls(model, img_path, result_dir)\n",
        "\n",
        "        if wall_segments:\n",
        "            all_results[os.path.basename(img_path)] = {\n",
        "                \"segments_count\": len(wall_segments),\n",
        "                \"segments\": wall_segments\n",
        "            }\n",
        "\n",
        "    # Save summary of results\n",
        "    summary_path = os.path.join(result_dir, 'test_results_summary.json')\n",
        "    with open(summary_path, 'w') as f:\n",
        "        json.dump(all_results, f, indent=2)\n",
        "\n",
        "    print(f\"Test results saved to {summary_path}\")\n",
        "\n",
        "    # If in Colab, download the summary\n",
        "    if is_colab():\n",
        "        print(\"Downloading test results summary...\")\n",
        "        files.download(summary_path)\n",
        "\n",
        "    return all_results\n",
        "\n",
        "# Example usage\n",
        "def get_wall_coordinates_simple_format(model, image_path, result_dir='dataset/results'):\n",
        "    \"\"\"\n",
        "    Extract wall coordinates in simple (x1,y1,x2,y2,length) format\n",
        "    and save to CSV\n",
        "\n",
        "    Uses the existing extract_wall_coordinates function\n",
        "    \"\"\"\n",
        "    # Create results directory if it doesn't exist\n",
        "    os.makedirs(result_dir, exist_ok=True)\n",
        "\n",
        "    # Get base filename without extension\n",
        "    base_filename = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "    # Load and preprocess image\n",
        "    img = cv2.imread(image_path)\n",
        "    # Check if image was loaded successfully\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not read image at {image_path}\")\n",
        "        return None\n",
        "\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "    # For wall-to-wall model, we need a grayscale version\n",
        "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    img_gray = np.expand_dims(img_gray, axis=-1)\n",
        "    img_norm = img_gray.astype('float32') / 255.0\n",
        "\n",
        "    # Predict mask\n",
        "    pred_mask = model.predict(np.expand_dims(img_norm, axis=0))[0]\n",
        "    binary_mask = (pred_mask > 0.5).astype(np.uint8) * 255\n",
        "\n",
        "    # Extract wall coordinates using existing function\n",
        "    wall_segments, skeleton = extract_wall_coordinates(binary_mask)\n",
        "\n",
        "    # Convert to simple format (x1,y1,x2,y2,length)\n",
        "    wall_coords = []\n",
        "    for wall in wall_segments:\n",
        "        x1 = wall['points'][0]['x']\n",
        "        y1 = wall['points'][0]['y']\n",
        "        x2 = wall['points'][1]['x']\n",
        "        y2 = wall['points'][1]['y']\n",
        "        length = wall['length']\n",
        "        wall_coords.append([x1, y1, x2, y2, length])\n",
        "\n",
        "    wall_coords = np.array(wall_coords) if wall_coords else np.empty((0, 5))\n",
        "\n",
        "    # Save to CSV\n",
        "    csv_path = os.path.join(result_dir, f\"{base_filename}_wall_coordinates.csv\")\n",
        "    np.savetxt(\n",
        "        csv_path,\n",
        "        wall_coords,\n",
        "        delimiter=',',\n",
        "        header='x1,y1,x2,y2,length',\n",
        "        comments='',\n",
        "        fmt='%d,%d,%d,%d,%.2f'\n",
        "    )\n",
        "\n",
        "    print(f\"Found {len(wall_coords)} wall segments\")\n",
        "    print(f\"Wall coordinates saved to {csv_path}\")\n",
        "\n",
        "    # If in Colab, download the file\n",
        "    if is_colab():\n",
        "        print(\"Downloading CSV file...\")\n",
        "        files.download(csv_path)\n",
        "\n",
        "    return wall_coords\n",
        "\n",
        "\n",
        "# Main function to run in Google Colab\n",
        "def run_wall_segmentation_tool_colab():\n",
        "    \"\"\"Main function to run the wall segmentation tool in Google Colab\"\"\"\n",
        "    # Check if running in Colab\n",
        "    if not is_colab():\n",
        "        print(\"This function is designed to run in Google Colab.\")\n",
        "        print(\"If you're not in Colab, please use the other functions directly.\")\n",
        "        return\n",
        "\n",
        "    # Setup directories\n",
        "    setup_directories()\n",
        "\n",
        "    # Display menu\n",
        "    print(\"\\n--- Wall Segmentation Tool for Google Colab ---\")\n",
        "    print(\"1. Upload Wall Images\")\n",
        "    print(\"2. Upload Test Images\")\n",
        "    print(\"3. Train Model\")\n",
        "    print(\"4. Test Model on Test Images\")\n",
        "    print(\"5. Extract Walls Directly (No Deep Learning)\")\n",
        "    print(\"6. Download Model\")\n",
        "    print(\"7. Upload and Load Existing Model\")\n",
        "    print(\"8. Extract Wall Coordinates (x1,y1,x2,y2,length) Format\")\n",
        "    print(\"9. Exit\")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"\\nEnter your choice (1-9): \")\n",
        "\n",
        "        if choice == \"1\":\n",
        "            # Upload wall images\n",
        "            upload_files('dataset/walls')\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            # Upload test images\n",
        "            upload_files('dataset/test')\n",
        "\n",
        "        elif choice == \"3\":\n",
        "            # Train model\n",
        "            print(\"Training model on uploaded wall images...\")\n",
        "            model, _ = train_simple_model()\n",
        "\n",
        "        elif choice == \"4\":\n",
        "            # Test model\n",
        "            model_path = os.path.join('dataset', 'model', 'simple_walls_best.h5')\n",
        "            if not os.path.exists(model_path):\n",
        "                print(\"No trained model found. Please train the model first.\")\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                model = load_model(model_path)\n",
        "                print(\"Model loaded successfully.\")\n",
        "                test_model(model)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading model: {e}\")\n",
        "\n",
        "        elif choice == \"5\":\n",
        "            # Extract walls directly\n",
        "            # First, upload a binary wall image\n",
        "            print(\"Please upload a binary wall image...\")\n",
        "            uploaded = upload_files('dataset/test')\n",
        "\n",
        "            if uploaded:\n",
        "                image_path = os.path.join('dataset', 'test', uploaded[0])\n",
        "                print(f\"Processing {image_path}...\")\n",
        "                extract_walls_directly(image_path)\n",
        "\n",
        "        elif choice == \"6\":\n",
        "            # Download model\n",
        "            model_path = os.path.join('dataset', 'model', 'simple_walls_best.h5')\n",
        "            if os.path.exists(model_path):\n",
        "                print(\"Downloading trained model...\")\n",
        "                files.download(model_path)\n",
        "            else:\n",
        "                print(\"No trained model found. Please train the model first.\")\n",
        "\n",
        "        elif choice == \"7\":\n",
        "            # Upload and load existing model\n",
        "            print(\"Please upload your trained model (.h5 file)...\")\n",
        "            uploaded = upload_files('dataset/model')\n",
        "\n",
        "            if uploaded:\n",
        "                model_path = os.path.join('dataset', 'model', uploaded[0])\n",
        "                try:\n",
        "                    model = load_model(model_path)\n",
        "                    print(\"Model loaded successfully.\")\n",
        "\n",
        "                    # Ask if they want to test it\n",
        "                    test_choice = input(\"Do you want to test the model on your test images? (y/n): \")\n",
        "                    if test_choice.lower() == 'y':\n",
        "                        test_model(model)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error loading model: {e}\")\n",
        "\n",
        "        elif choice == \"8\":\n",
        "        # Extract wall coordinates in (x1,y1,x2,y2,length) format\n",
        "        # First check if model exists\n",
        "          model_path = os.path.join('dataset', 'model', 'simple_walls_best.h5')\n",
        "\n",
        "          if not os.path.exists(model_path):\n",
        "              # Ask if they want to upload a model\n",
        "              upload_choice = input(\"No trained model found. Do you want to upload one? (y/n): \")\n",
        "              if upload_choice.lower() == 'y':\n",
        "                  uploaded = upload_files('dataset/model')\n",
        "                  if uploaded:\n",
        "                      model_path = os.path.join('dataset', 'model', uploaded[0])\n",
        "                  else:\n",
        "                      print(\"No model uploaded. Returning to menu.\")\n",
        "                      continue\n",
        "              else:\n",
        "                  print(\"A model is required for wall coordinate extraction. Returning to menu.\")\n",
        "                  continue\n",
        "\n",
        "          # Now check for test images or ask to upload one\n",
        "          test_dir = 'dataset/test'\n",
        "          test_images = glob.glob(os.path.join(test_dir, '*.*'))\n",
        "\n",
        "          if not test_images:\n",
        "              print(\"No test images found. Please upload an image to process.\")\n",
        "              uploaded = upload_files(test_dir)\n",
        "              if not uploaded:\n",
        "                  print(\"No images uploaded. Returning to menu.\")\n",
        "                  continue\n",
        "              test_images = [os.path.join(test_dir, uploaded[0])]\n",
        "\n",
        "          # Let user select an image if multiple are available\n",
        "          if len(test_images) > 1:\n",
        "              print(\"\\nAvailable test images:\")\n",
        "              for i, img_path in enumerate(test_images):\n",
        "                  print(f\"{i+1}. {os.path.basename(img_path)}\")\n",
        "\n",
        "              img_choice = input(f\"Select image to process (1-{len(test_images)}): \")\n",
        "              try:\n",
        "                  img_idx = int(img_choice) - 1\n",
        "                  if 0 <= img_idx < len(test_images):\n",
        "                      image_path = test_images[img_idx]\n",
        "                  else:\n",
        "                      print(\"Invalid selection. Using the first image.\")\n",
        "                      image_path = test_images[0]\n",
        "              except ValueError:\n",
        "                  print(\"Invalid input. Using the first image.\")\n",
        "                  image_path = test_images[0]\n",
        "          else:\n",
        "              image_path = test_images[0]\n",
        "\n",
        "          # Load model\n",
        "          try:\n",
        "              model = load_model(model_path)\n",
        "              print(f\"Model loaded successfully from {model_path}\")\n",
        "              print(f\"Processing image: {os.path.basename(image_path)}\")\n",
        "\n",
        "              # Extract and save coordinates\n",
        "              wall_coords = get_wall_coordinates_simple_format(model, image_path)\n",
        "\n",
        "              if wall_coords is not None and wall_coords.size > 0:\n",
        "                  print(\"First 5 walls:\")\n",
        "                  for i, wall in enumerate(wall_coords[:5]):\n",
        "                      print(f\"Wall {i+1}: x1={int(wall[0])}, y1={int(wall[1])}, x2={int(wall[2])}, y2={int(wall[3])}, length={wall[4]:.2f}\")\n",
        "              else:\n",
        "                  print(\"No walls detected in the image.\")\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"Error processing image: {e}\")\n",
        "\n",
        "        elif choice == \"9\":\n",
        "            # Exit\n",
        "            print(\"Exiting...\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"Invalid choice. Please try again.\")\n",
        "\n",
        "\n",
        "# Entry point\n",
        "if __name__ == \"__main__\":\n",
        "    # If running in Colab, run the Colab-specific function\n",
        "    if is_colab():\n",
        "        run_wall_segmentation_tool_colab()\n",
        "    else:\n",
        "        # If running locally, provide a simple interface\n",
        "        print(\"Wall Segmentation Tool\")\n",
        "        print(\"1. Train model\")\n",
        "        print(\"2. Extract walls directly\")\n",
        "        print(\"3. Predict with trained model\")\n",
        "        print(\"4. Exit\")\n",
        "\n",
        "        choice = input(\"Enter your choice (1-4): \")\n",
        "\n",
        "        if choice == \"1\":\n",
        "            data_dir = input(\"Enter data directory path (or press Enter for default): \")\n",
        "            if data_dir:\n",
        "                train_simple_model(data_dir)\n",
        "            else:\n",
        "                train_simple_model()\n",
        "\n",
        "        elif choice == \"2\":\n",
        "            image_path = input(\"Enter image path: \")\n",
        "            if image_path:\n",
        "                extract_walls_directly(image_path)\n",
        "            else:\n",
        "                print(\"Error: Image path required\")\n",
        "\n",
        "        elif choice == \"3\":\n",
        "            model_path = input(\"Enter model path: \")\n",
        "            image_path = input(\"Enter image path: \")\n",
        "\n",
        "            if model_path and image_path:\n",
        "                try:\n",
        "                    model = load_model(model_path)\n",
        "                    predict_walls(model, image_path)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error: {e}\")\n",
        "            else:\n",
        "                print(\"Error: Both model and image paths required\")\n",
        "\n",
        "        elif choice == \"4\":\n",
        "            print(\"Exiting...\")\n",
        "        else:\n",
        "            print(\"Invalid choice. Please run again.\")"
      ],
      "metadata": {
        "id": "Ba3qyduaP_Tv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "outputId": "8bd7d38a-0270-4053-bdb4-5de856ca2e4e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory structure created:\n",
            "- dataset/walls: Upload your wall images here\n",
            "- dataset/test: Upload your test images here\n",
            "- dataset/model: Trained models will be saved here\n",
            "- dataset/results: Results will be saved here\n",
            "\n",
            "--- Wall Segmentation Tool for Google Colab ---\n",
            "1. Upload Wall Images\n",
            "2. Upload Test Images\n",
            "3. Train Model\n",
            "4. Test Model on Test Images\n",
            "5. Extract Walls Directly (No Deep Learning)\n",
            "6. Download Model\n",
            "7. Upload and Load Existing Model\n",
            "8. Extract Wall Coordinates (x1,y1,x2,y2,length) Format\n",
            "9. Exit\n",
            "\n",
            "Enter your choice (1-9): 8\n",
            "\n",
            "Available test images:\n",
            "1. 00001000.jpg\n",
            "2. 00010057.jpg\n",
            "3. 00010062.jpg\n",
            "4. 00010058.jpg\n",
            "5. 00010063.jpg\n",
            "6. 00010090.jpg\n",
            "7. 00010059.jpg\n",
            "Select image to process (1-7): 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully from dataset/model/simple_walls_best.h5\n",
            "Processing image: 00010058.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7fd172e82f20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804ms/step\n",
            "Found 44 wall segments\n",
            "Wall coordinates saved to dataset/results/00010058_wall_coordinates.csv\n",
            "Downloading CSV file...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_59ecb28a-5de4-4d65-aa2e-8cbb3cc125b0\", \"00010058_wall_coordinates.csv\", 980)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 walls:\n",
            "Wall 1: x1=256, y1=441, x2=410, y2=408, length=157.50\n",
            "Wall 2: x1=340, y1=195, x2=440, y2=174, length=102.18\n",
            "Wall 3: x1=74, y1=254, x2=225, y2=220, length=154.78\n",
            "Wall 4: x1=425, y1=103, x2=471, y2=316, length=217.91\n",
            "Wall 5: x1=222, y1=68, x2=407, y2=29, length=189.07\n",
            "\n",
            "Enter your choice (1-9): 9\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "azZfNP5JFaZR"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}